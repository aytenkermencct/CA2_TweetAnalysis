{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d15673",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in /home/hduser/.local/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /home/hduser/.local/lib/python3.10/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/hduser/.local/lib/python3.10/site-packages (from nltk>=3.1->textblob) (2022.8.17)\n",
      "Requirement already satisfied: tqdm in /home/hduser/.local/lib/python3.10/site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: joblib in /home/hduser/.local/lib/python3.10/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pydot in /home/hduser/.local/lib/python3.10/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/lib/python3/dist-packages (from pydot) (2.4.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pydotplus in /home/hduser/.local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in /usr/lib/python3/dist-packages (from pydotplus) (2.4.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: graphviz in /home/hduser/.local/lib/python3.10/site-packages (0.20.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/hduser/.local/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: joblib in /home/hduser/.local/lib/python3.10/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/hduser/.local/lib/python3.10/site-packages (from nltk) (2022.8.17)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: tqdm in /home/hduser/.local/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/lib/python3/dist-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/lib/python3/dist-packages (from scikit-learn) (1.21.5)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, joblib, scikit-learn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!pip install pydot\n",
    "!pip install pydotplus\n",
    "!pip install graphviz\n",
    "!pip install nltk\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7493c246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/hduser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/hduser/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/hduser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /home/hduser/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('sentiwordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "## lexicons\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "## visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import col, trim, first ,when,to_timestamp,udf, from_unixtime,regexp_replace,date_format,substring,StringType\n",
    "\n",
    "from pyspark.sql.types import ArrayType, IntegerType,DoubleType\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7aa2001",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").config(\"spark.driver.memory\", \"15g\").appName(\"CsvReader\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7caba11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:===========================================================(1 + 0) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## read csv \n",
    "twitter_data = spark.read.format(\"csv\").load(\"file:///home/hduser/Desktop/CA2_TweetAnalysis/ProjectTweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d01a45a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|_c0|       _c1|                 _c2|     _c3|            _c4|                 _c5|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7616aaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_c0', '_c1', '_c2', '_c3', '_c4', '_c5']\n"
     ]
    }
   ],
   "source": [
    "print(twitter_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "365d5825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "twitter_data = twitter_data.selectExpr(\"_c1 as id\", \"_c2 as date\", \"_c3 as flag\", \"_c4 as user\", \"_c5 as text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22ac4c6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------+---------------+--------------------+\n",
      "|        id|                date|    flag|           user|                text|\n",
      "+----------+--------------------+--------+---------------+--------------------+\n",
      "|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82eb2f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73e8f592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
      "Mon Apr 06 22:19:45 PDT 2009\n"
     ]
    }
   ],
   "source": [
    "#check tweet and date format\n",
    "first_row = twitter_data.first()\n",
    "print(first_row['text'])\n",
    "\n",
    "print(first_row['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83aa49a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
      "Mon Apr 06 22:19:45 2009\n"
     ]
    }
   ],
   "source": [
    "# Use regexp_replace to remove PDT from the date_string\n",
    "twitter_data = twitter_data.withColumn(\"date\", regexp_replace(twitter_data[\"date\"], \" PDT\", \"\"))\n",
    "\n",
    "first_row=twitter_data.first()\n",
    "print(first_row['text'])\n",
    "\n",
    "print(first_row['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ee8fdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------+---------------+--------------------+--------------------+-------------------+-------------------+\n",
      "|        id|                date|    flag|           user|                text|            new_date|          timestamp|     formatted_date|\n",
      "+----------+--------------------+--------+---------------+--------------------+--------------------+-------------------+-------------------+\n",
      "|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|Apr 06 22:19:45 2009|2009-04-06 22:19:45|2009 04 06 22:19:45|\n",
      "|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|Apr 06 22:19:49 2009|2009-04-06 22:19:49|2009 04 06 22:19:49|\n",
      "|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|Apr 06 22:19:53 2009|2009-04-06 22:19:53|2009 04 06 22:19:53|\n",
      "|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|Apr 06 22:19:57 2009|2009-04-06 22:19:57|2009 04 06 22:19:57|\n",
      "|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|Apr 06 22:19:57 2009|2009-04-06 22:19:57|2009 04 06 22:19:57|\n",
      "|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|Apr 06 22:20:00 2009|2009-04-06 22:20:00|2009 04 06 22:20:00|\n",
      "|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |Apr 06 22:20:03 2009|2009-04-06 22:20:03|2009 04 06 22:20:03|\n",
      "|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|Apr 06 22:20:03 2009|2009-04-06 22:20:03|2009 04 06 22:20:03|\n",
      "|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|Apr 06 22:20:05 2009|2009-04-06 22:20:05|2009 04 06 22:20:05|\n",
      "|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|Apr 06 22:20:09 2009|2009-04-06 22:20:09|2009 04 06 22:20:09|\n",
      "|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|Apr 06 22:20:16 2009|2009-04-06 22:20:16|2009 04 06 22:20:16|\n",
      "|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|Apr 06 22:20:17 2009|2009-04-06 22:20:17|2009 04 06 22:20:17|\n",
      "|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|Apr 06 22:20:19 2009|2009-04-06 22:20:19|2009 04 06 22:20:19|\n",
      "|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|Apr 06 22:20:19 2009|2009-04-06 22:20:19|2009 04 06 22:20:19|\n",
      "|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|Apr 06 22:20:20 2009|2009-04-06 22:20:20|2009 04 06 22:20:20|\n",
      "|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|Apr 06 22:20:20 2009|2009-04-06 22:20:20|2009 04 06 22:20:20|\n",
      "|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|Apr 06 22:20:22 2009|2009-04-06 22:20:22|2009 04 06 22:20:22|\n",
      "|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |Apr 06 22:20:25 2009|2009-04-06 22:20:25|2009 04 06 22:20:25|\n",
      "|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|Apr 06 22:20:31 2009|2009-04-06 22:20:31|2009 04 06 22:20:31|\n",
      "|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|Apr 06 22:20:34 2009|2009-04-06 22:20:34|2009 04 06 22:20:34|\n",
      "+----------+--------------------+--------+---------------+--------------------+--------------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#formated date columns as yyyy mm dd hh:mm:ss format\n",
    "df=twitter_data\n",
    "df = df.withColumn(\"new_date\", substring(col(\"date\"), 5,25))\n",
    "# Use the to_timestamp function to convert the date_string to a timestamp\n",
    "df = df.withColumn(\"timestamp\", to_timestamp(df[\"new_date\"], \"MMM dd HH:mm:ss yyyy\"))\n",
    "\n",
    "# Use the date_format function to format the timestamp as desired\n",
    "df = df.withColumn(\"formatted_date\", date_format(df[\"timestamp\"], \"yyyy MM dd HH:mm:ss\"))\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "988f14a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'date',\n",
       " 'flag',\n",
       " 'user',\n",
       " 'text',\n",
       " 'new_date',\n",
       " 'timestamp',\n",
       " 'formatted_date']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "177cf3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------------+--------------------+-------------------+\n",
      "|        id|    flag|           user|                text|     formatted_date|\n",
      "+----------+--------+---------------+--------------------+-------------------+\n",
      "|1467810369|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|2009 04 06 22:19:45|\n",
      "|1467810672|NO_QUERY|  scotthamilton|is upset that he ...|2009 04 06 22:19:49|\n",
      "|1467810917|NO_QUERY|       mattycus|@Kenichan I dived...|2009 04 06 22:19:53|\n",
      "|1467811184|NO_QUERY|        ElleCTF|my whole body fee...|2009 04 06 22:19:57|\n",
      "|1467811193|NO_QUERY|         Karoli|@nationwideclass ...|2009 04 06 22:19:57|\n",
      "|1467811372|NO_QUERY|       joy_wolf|@Kwesidei not the...|2009 04 06 22:20:00|\n",
      "|1467811592|NO_QUERY|        mybirch|         Need a hug |2009 04 06 22:20:03|\n",
      "|1467811594|NO_QUERY|           coZZ|@LOLTrish hey  lo...|2009 04 06 22:20:03|\n",
      "|1467811795|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|2009 04 06 22:20:05|\n",
      "|1467812025|NO_QUERY|        mimismo|@twittera que me ...|2009 04 06 22:20:09|\n",
      "|1467812416|NO_QUERY| erinx3leannexo|spring break in p...|2009 04 06 22:20:16|\n",
      "|1467812579|NO_QUERY|   pardonlauren|I just re-pierced...|2009 04 06 22:20:17|\n",
      "|1467812723|NO_QUERY|           TLeC|@caregiving I cou...|2009 04 06 22:20:19|\n",
      "|1467812771|NO_QUERY|robrobbierobert|@octolinz16 It it...|2009 04 06 22:20:19|\n",
      "|1467812784|NO_QUERY|    bayofwolves|@smarrison i woul...|2009 04 06 22:20:20|\n",
      "|1467812799|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|2009 04 06 22:20:20|\n",
      "|1467812964|NO_QUERY| lovesongwriter|Hollis' death sce...|2009 04 06 22:20:22|\n",
      "|1467813137|NO_QUERY|       armotley|about to file taxes |2009 04 06 22:20:25|\n",
      "|1467813579|NO_QUERY|     starkissed|@LettyA ahh ive a...|2009 04 06 22:20:31|\n",
      "|1467813782|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|2009 04 06 22:20:34|\n",
      "+----------+--------+---------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df[['id',\n",
    " 'flag',\n",
    " 'user',\n",
    " 'text',\n",
    " 'formatted_date']]\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055e65dd",
   "metadata": {},
   "source": [
    "## Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf877e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c87e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "##mongodb connection\n",
    "import pymongo\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"twitter_data\"]\n",
    "collection = db[\"tweets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5318376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean collection \n",
    "#collection.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43eb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#insert data to mongodb \n",
    "rows = df.collect()\n",
    "data_list = [row.asDict() for row in rows]\n",
    "\n",
    "#insert\n",
    "for data in data_list:\n",
    "    collection.insert_one(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11ff9c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2391723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data from mongodb\n",
    "# Retrieve the data from the MongoDB collection\n",
    "mongo_data = list(collection.find().limit(5))\n",
    "mongo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3e32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_count = collection.count_documents({})\n",
    "record_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd107d",
   "metadata": {},
   "source": [
    "## Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d957dbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------------+--------------------+-------------------+\n",
      "|        id|    flag|           user|                text|     formatted_date|\n",
      "+----------+--------+---------------+--------------------+-------------------+\n",
      "|1467810369|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|2009 04 06 22:19:45|\n",
      "|1467810672|NO_QUERY|  scotthamilton|is upset that he ...|2009 04 06 22:19:49|\n",
      "|1467810917|NO_QUERY|       mattycus|@Kenichan I dived...|2009 04 06 22:19:53|\n",
      "|1467811184|NO_QUERY|        ElleCTF|my whole body fee...|2009 04 06 22:19:57|\n",
      "|1467811193|NO_QUERY|         Karoli|@nationwideclass ...|2009 04 06 22:19:57|\n",
      "|1467811372|NO_QUERY|       joy_wolf|@Kwesidei not the...|2009 04 06 22:20:00|\n",
      "|1467811592|NO_QUERY|        mybirch|         Need a hug |2009 04 06 22:20:03|\n",
      "|1467811594|NO_QUERY|           coZZ|@LOLTrish hey  lo...|2009 04 06 22:20:03|\n",
      "|1467811795|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|2009 04 06 22:20:05|\n",
      "|1467812025|NO_QUERY|        mimismo|@twittera que me ...|2009 04 06 22:20:09|\n",
      "|1467812416|NO_QUERY| erinx3leannexo|spring break in p...|2009 04 06 22:20:16|\n",
      "|1467812579|NO_QUERY|   pardonlauren|I just re-pierced...|2009 04 06 22:20:17|\n",
      "|1467812723|NO_QUERY|           TLeC|@caregiving I cou...|2009 04 06 22:20:19|\n",
      "|1467812771|NO_QUERY|robrobbierobert|@octolinz16 It it...|2009 04 06 22:20:19|\n",
      "|1467812784|NO_QUERY|    bayofwolves|@smarrison i woul...|2009 04 06 22:20:20|\n",
      "|1467812799|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|2009 04 06 22:20:20|\n",
      "|1467812964|NO_QUERY| lovesongwriter|Hollis' death sce...|2009 04 06 22:20:22|\n",
      "|1467813137|NO_QUERY|       armotley|about to file taxes |2009 04 06 22:20:25|\n",
      "|1467813579|NO_QUERY|     starkissed|@LettyA ahh ive a...|2009 04 06 22:20:31|\n",
      "|1467813782|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|2009 04 06 22:20:34|\n",
      "+----------+--------+---------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## spark sql\n",
    "df.createOrReplaceTempView(\"twitter_data\")\n",
    "result = spark.sql(\"SELECT * FROM twitter_data\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15c70378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f722279f",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df78f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text \n",
    "# Store the stopwords into the object named as \"stop_words\"\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Store the string.punctuation into an object punct\n",
    "punct = string.punctuation\n",
    "\n",
    "# Initialise an object using a method PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1026c392",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|@switchfoot http:...|\n",
      "|is upset that he ...|\n",
      "|@Kenichan I dived...|\n",
      "|my whole body fee...|\n",
      "|@nationwideclass ...|\n",
      "|@Kwesidei not the...|\n",
      "|         Need a hug |\n",
      "|@LOLTrish hey  lo...|\n",
      "|@Tatiana_K nope t...|\n",
      "|@twittera que me ...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=df.select(\"text\")\n",
    "X.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37aa7f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/hduser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/hduser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[Stage 28:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------+--------------------+\n",
      "|text                                                                                                                 |text_processed                                                          |sentiment_score     |\n",
      "+---------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------+--------------------+\n",
      "|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  |switchfoot http awww bummer shoulda got david carr third day            |0.2                 |\n",
      "|is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!      |upset ca update facebook texting might cry result school today also blah|0.0                 |\n",
      "|@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                            |kenichan dived many times ball managed save rest go bounds              |0.5                 |\n",
      "|my whole body feels itchy and like its on fire                                                                       |whole body feels itchy like fire                                        |0.2                 |\n",
      "|@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.       |nationwideclass behaving mad ca see                                     |-0.625              |\n",
      "|@Kwesidei not the whole crew                                                                                         |kwesidei whole crew                                                     |0.2                 |\n",
      "|Need a hug                                                                                                           |need hug                                                                |0.0                 |\n",
      "|@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?                  |loltrish hey long time see yes rains bit bit lol fine thanks            |0.3416666666666667  |\n",
      "|@Tatiana_K nope they didn't have it                                                                                  |nope                                                                    |0.0                 |\n",
      "|@twittera que me muera ?                                                                                             |twittera que muera                                                      |0.0                 |\n",
      "|spring break in plain city... it's snowing                                                                           |spring break plain city snowing                                         |-0.21428571428571427|\n",
      "|I just re-pierced my ears                                                                                            |ears                                                                    |0.0                 |\n",
      "|@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .                       |caregiving could bear watch thought ua loss embarrassing                |0.0                 |\n",
      "|@octolinz16 It it counts, idk why I did either. you never talk to me anymore                                         |counts idk either never talk anymore                                    |0.0                 |\n",
      "|@smarrison i would've been the first, but i didn't have a gun.    not really though, zac snyder's just a doucheclown.|smarrison would first gun really though zac snyder doucheclown          |0.225               |\n",
      "|@iamjazzyfizzle I wish I got to watch it with you!! I miss you and @iamlilnicki  how was the premiere?!              |iamjazzyfizzle wish got watch miss iamlilnicki premiere                 |0.0                 |\n",
      "|Hollis' death scene will hurt me severely to watch on film  wry is directors cut not out now?                        |hollis death scene hurt severely watch film wry directors cut           |0.0                 |\n",
      "|about to file taxes                                                                                                  |file taxes                                                              |0.0                 |\n",
      "|@LettyA ahh ive always wanted to see rent  love the soundtrack!!                                                     |lettya ahh ive always wanted see rent love soundtrack                   |0.5                 |\n",
      "|@FakerPattyPattz Oh dear. Were you drinking out of the forgotten table drinks?                                       |fakerpattypattz oh dear drinking forgotten table drinks                 |0.0                 |\n",
      "+---------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Download NLTK stopwords data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define a function to tokenize, remove stopwords, and clean punctuation\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    clean_words = [word.lower() for word in filtered_words if word.isalpha()]\n",
    "\n",
    "    # Join the cleaned words into a single string\n",
    "    return \" \".join(clean_words)\n",
    "\n",
    "# Create a user-defined function (UDF) for text preprocessing\n",
    "preprocess_udf = udf(preprocess_text, StringType())\n",
    "\n",
    "# Apply the UDF to the DataFrame\n",
    "processed_df = X.withColumn(\"text_processed\", preprocess_udf(col(\"text\")))\n",
    "\n",
    "# Perform TextBlob sentiment analysis on the preprocessed text\n",
    "def analyze_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "# Create a UDF for sentiment analysis\n",
    "sentiment_udf = udf(analyze_sentiment, StringType())\n",
    "\n",
    "# Apply the UDF to the preprocessed DataFrame\n",
    "sentiment_df = processed_df.withColumn(\"sentiment_score\", sentiment_udf(col(\"text_processed\")))\n",
    "\n",
    "# Show the DataFrame with sentiment scores\n",
    "sentiment_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c634730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 29:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------+---------------+\n",
      "|text_processed                                                          |sentiment_score|\n",
      "+------------------------------------------------------------------------+---------------+\n",
      "|switchfoot http awww bummer shoulda got david carr third day            |0.2            |\n",
      "|upset ca update facebook texting might cry result school today also blah|0.0            |\n",
      "+------------------------------------------------------------------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sentiment_df.select(\"text_processed\",\"sentiment_score\").show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0be21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e9352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b3289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96753722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890cd7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0373a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04083a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdeeebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
